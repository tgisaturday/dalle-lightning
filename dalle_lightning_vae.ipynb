{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dalle-lightning-vae.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "u3ya_76q6t8V"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN6AI4JGgUAdtbpeRo0628h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afiaka87/dalle-lightning/blob/colab_notebook/dalle_lightning_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTOnOX-Wsw-1"
      },
      "source": [
        "# Train a `VAE` with [`dalle-lightning`](https://github.com/tgisaturday/dalle-lightning)\n",
        "\n",
        "[`dalle-lightning`](https://github.com/tgisaturday/dalle-lightning) from [`tgisaturday`](https://github.com/tgisaturday)\n",
        "\n",
        "Train a `Variational Auto-Encoder` for vision tasks using TPUs or GPUs.\n",
        "\n",
        "\n",
        "Full usage instructions in last cell of notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNFiz92zPVRQ",
        "cellView": "form"
      },
      "source": [
        "# @title Licensed under the MIT License\n",
        "\n",
        "# Copyright (c) 2021 Sam Sepiol - https://github.com/afiaka87\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ER2NxRCw_3W"
      },
      "source": [
        "\n",
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzSLwbDUEpuD",
        "cellView": "form"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "#@title GPU or TPU Install\n",
        "use_tpus = True #@param {type: 'boolean'}\n",
        "\n",
        "if use_tpus:\n",
        "    %pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!rm -rf /content/lib/dalle-lightning/\n",
        "!git clone https://github.com/tgisaturday/dalle-lightning.git /content/lib/dalle-lightning\n",
        "%pip install -r /content/lib/dalle-lightning/requirements.txt\n",
        "\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUhxTpHmvuBQ"
      },
      "source": [
        "# (Optional) - Download Images to Train On"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EJt9Of4GAOf",
        "cellView": "form"
      },
      "source": [
        "#@title ### Create paths and download dataset.\n",
        "#@markdown - By default, the COCO 2017 256px Training dataset (1.1 GB) will be used. \n",
        "#@markdown - **May take 5 minutes or more to download and split.**  \n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "data_filename='dataset.tar.gz'\n",
        "data_url='https://www.dropbox.com/s/txuzmca8ugk9uoe/coco2017.tar.gz?dl=0' #@param {type: 'raw'}\n",
        "\n",
        "tmp_dir='/content/tmp' \n",
        "data_dir='/content/data'  \n",
        "log_path='/content/vae_logs'\n",
        "dl_dir=os.path.join(tmp_dir, 'download')\n",
        "data_dl_path=os.path.join(dl_dir, data_filename)\n",
        "untar_dir=os.path.join(tmp_dir, 'untar/') \n",
        "train_path=Path(os.path.join(data_dir,'train/class/'))\n",
        "val_path=Path(os.path.join(data_dir, 'val/class/'))\n",
        " \n",
        "os.makedirs(tmp_dir, exist_ok=True) \n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "os.makedirs(log_path, exist_ok=True)\n",
        "os.makedirs(dl_dir, exist_ok=True) \n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(val_path, exist_ok=True)\n",
        "os.makedirs(untar_dir, exist_ok=True)\n",
        " \n",
        "#@markdown **TODO** - use academictorrents with `aria2` instead. \n",
        "# see github.com/robvanvolt/DALLE-datasets for an example \n",
        "print(\"Attmpting to download COCO 2017 Training Set...\")\n",
        "print(\"Re-run cell to finish in case of interruption.\") \n",
        "# TODO - convert to pure python\n",
        "!(wget --continue $data_url -O $data_dl_path);\n",
        "\n",
        "# Extract to tmp folder\n",
        "print(\"Attempting to extract.\")\n",
        "# TODO - convert to pure python\n",
        "!(tar --keep-old-files \\\n",
        "--extract \\\n",
        "--verbose \\\n",
        "--file $data_dl_path \\\n",
        "--directory $untar_dir);\n",
        "\n",
        "clear_output()\n",
        "print(\"Finished downloading and extracting COCO 2017.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xWfdyg4u--nJ"
      },
      "source": [
        "#@title ### Split dataset into training and validation folders.  May take awhile. \n",
        "\n",
        "import random\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "_path = Path(untar_dir)\n",
        "image_files = [\n",
        "    *_path.glob('**/*.png'), *_path.glob('**/*.jpg'),\n",
        "    *_path.glob('**/*.jpeg'), *_path.glob('**/*.bmp')\n",
        "]\n",
        "\n",
        "# Count\n",
        "num_images_total = len(image_files)\n",
        "random.shuffle(image_files)\n",
        "\n",
        "assert len(image_files) > 0, 'Images not found. Re-run prior cell if needed.'\n",
        "\n",
        "# Split\n",
        "\n",
        "# Validation\n",
        "num_images_val=int(num_images_total*0.2)   \n",
        "val_data = image_files[num_images_val:] \n",
        "for val_image_path in val_data:\n",
        "    dest = os.path.join(val_path.absolute(), val_image_path.name)\n",
        "    try:\n",
        "        val_image_path.rename(dest)\n",
        "    except FileNotFoundError as already_moved_ex:\n",
        "        print(\"Image not found. Skipping.\")\n",
        "print(f\"Moved {num_images_val} images to {val_path}\")\n",
        "\n",
        "# Training\n",
        "num_images_train=int(num_images_total*0.8)\n",
        "train_data = image_files[:num_images_train]\n",
        "for train_image_path in train_data:\n",
        "    dest = os.path.join(train_path.absolute(), train_image_path.name)\n",
        "    try:\n",
        "        train_image_path.rename(dest)\n",
        "    except FileNotFoundError as already_moved_ex:\n",
        "        print(\"Image not found. Skipping.\")\n",
        "print(f\"Moved {num_images_train} images to {train_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTvqWHyRqR9U"
      },
      "source": [
        "# Train a `Variational Auto-Encoder`\n",
        "## A `VAE` represents patches of RGB pixels efficiently.\n",
        "\n",
        "Pretrained\n",
        "- vqgan: `Vector Quantized Variational Autoencoders` from `CompVis`\n",
        "- gvqvae: `Gumbel VQ-VAE` from `OpenAI`\n",
        "\n",
        "Other\n",
        "- evqvae: `EMA-Decay VQ-GAN`\n",
        "- gvqgan: `GumbelVQGAN`\n",
        "- vqvae: `Vanilla VQ-VAE`\n",
        "- evqvae: `EMA-Decay VQ-VAE`\n",
        "- vqvae2: `VQ-VAE2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjIgVuR86p_Y",
        "cellView": "form"
      },
      "source": [
        "%%writefile /content/tmp/run.sh\n",
        "#@title Configuration\n",
        "# model\n",
        "model=\"vqgan\" #@param  ['vqgan','evqgan','gvqgan','vqvae','evqvae','gvqvae','vqvae2']\n",
        "# training\n",
        "epochs=30 #@param {'type': 'raw'}\n",
        "learning_rate=4.5e-6 #@param {'type': 'number' }\n",
        "precision=16 #@param {'type': 'integer' }\n",
        "batch_size=8 #@param {'type': 'raw'}\n",
        "num_workers=8 #@param {'type': 'raw'} \n",
        "# fake_data=True #@param {'type': 'boolean' }\n",
        "use_tpus=True #@param {'type': 'boolean' }\n",
        "embed_dim=256 #@param  {'type': 'number'}\n",
        "codebook_dim=1024 #@param  {'type': 'integer'}\n",
        "double_z=False #@param  {'type': 'string'}\n",
        "z_channels=256 #@param  {'type': 'integer'}\n",
        "resolution=256 #@param  {'type': 'integer'}\n",
        "in_channels=3 #@param  {'type': 'integer'}\n",
        "out_channels=3 #@param  {'type': 'integer'}\n",
        "hidden_dim=128 #@param  {'type': 'integer'}\n",
        "ch_mult=1,1,2,2,4 #@param  {'type': 'raw'}\n",
        "num_res_blocks=2 #@param  {'type': 'integer'}\n",
        "attn_resolutions=16 #@param  {'type': 'raw'}\n",
        "\n",
        "\n",
        "# modifiable\n",
        "resume=False #@param {type: 'boolean'}\n",
        "dropout=0.1 #@param {type: 'number'}\n",
        "rescale_img_size=256 #@param {type: 'number'}\n",
        "resize_ratio=0.75 #@param {type: 'number'}\n",
        "# test=True #@param {type: 'boolean'}\n",
        "seed=8675309\n",
        "\n",
        "python '/content/lib/dalle-lightning/train_vae.py' \\\n",
        "    --epochs $epochs \\\n",
        "    --learning_rate $learning_rate \\\n",
        "    --precision $precision \\\n",
        "    --batch_size $batch_size \\\n",
        "    --num_workers $num_workers \\\n",
        "    --use_tpus \\\n",
        "    --model $model \\\n",
        "    --fake_data \\\n",
        "    --train_dir \"/content/data/train/\" \\\n",
        "    --val_dir \"/content/data/test\" \\\n",
        "    --ckpt_path \"/content/vae_logs/last.ckpt\"  \\\n",
        "    --log_dir \"/content/vae_logs/\" \\\n",
        "    --embed_dim $embed_dim \\\n",
        "    --codebook_dim $codebook_dim \\\n",
        "    --double_z $double_z \\\n",
        "    --z_channels $z_channels \\\n",
        "    --resolution $resolution \\\n",
        "    --hidden_dim $hidden_dim \\\n",
        "    --ch_mult $ch_mult \\\n",
        "    --num_res_blocks $num_res_blocks \\\n",
        "    --attn_resolutions $attn_resolutions \\\n",
        "    --dropout $dropout \\\n",
        "    --img_size $rescale_img_size \\\n",
        "    --seed $seed \\\n",
        "    --resize_ratio $resize_ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lTkMmRZzlTW"
      },
      "source": [
        "!(sh /content/tmp/run.sh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ya_76q6t8V"
      },
      "source": [
        "# Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIynGZnEK4G0"
      },
      "source": [
        "### Paths\n",
        "```sh\n",
        "--train_dir /content/data/train \\\n",
        "--val_dir /content/data/val \\\n",
        "--test_dir /content/data/test \\\n",
        "--log_dir /content/vae_logs \\\n",
        "--ckpt_path /content/vae_logs/final.ckpt \\\n",
        "```\n",
        "\n",
        "### Training \n",
        "\n",
        "#### Training - General\n",
        "```sh\n",
        "--batch_size 8 \\\n",
        "--epochs 30 \\\n",
        "--precision 16 --use_tpus True \\\n",
        "--fake_data False --resume False --seed 8675309 \\\n",
        "```\n",
        "\n",
        "\n",
        "#### Training - Learning Rate\n",
        "```sh\n",
        "--learning_rate 4.5e-6 \\\n",
        "--lr_decay_rate 1e-8 \\\n",
        "--starting_temp 0.5 \\\n",
        "--temp_min 0.1 \\\n",
        "--anneal_rate  \\\n",
        "--img_size 256 \\\n",
        "--resize_ratio 0.75 \\\n",
        "--dropout 0.1\n",
        "--test False\n",
        "```\n",
        "\n",
        "### Model\n",
        "\n",
        "#### Model - Hyperparameters\n",
        "```sh\n",
        "--model vqgan \\\n",
        "--embed_dim 256 --codebook_dim 1024 \\\n",
        "--double_z false \\\n",
        "--z_channels 256 --resolution 256 \\\n",
        "--hidden_dim 128 --ch_mult 128 --attn_resolutions 16 \\\n",
        "--in_channels 3 --out_channels 3 \\\n",
        "--num_res_blocks 2 \\\n",
        "--dropout 0.1\n",
        "```\n",
        "\n",
        "#### Model - Loss\n",
        "```sh\n",
        "--smooth_l1_loss --kl_loss_weight \\\n",
        "--disc_conditional --disc_in_channels \\\n",
        "--disc_start --disc_weight \\\n",
        "--codebook_weight \n",
        "```\n",
        "\n",
        "### (Work-in-Progress) - `vqvae2`\n",
        "```sh\n",
        "--num_res_ch  --decay --latent_weight\n",
        "```  "
      ]
    }
  ]
}