
——————————————————————————————
# Single TPU usage

gcloud services enable tpu.googleapis.com

gcloud alpha compute tpus tpu-vm create tpu-vm-3 --zone=europe-west4-a --accelerator-type=v3-8 --version=v2-alpha 


gcloud alpha compute tpus tpu-vm ssh tpu-vm-1 --zone europe-west4-a --project lgai-vision-tpu

export XRT_TPU_CONFIG="localservice;0;localhost:51011"

python3 -m torch_xla.core.xrt_run_server --port 51011 --restart

python3 dalle-lightning/train_vae.py --use_tpus --model vqvae --fake_data

python3 dalle-lightning/train_dalle.py --use_tpus --vae vqvae --fake_data

export TF_CPP_VMODULE=tensor=5,computation_client=5,xrt_computation_client=5,aten_xla_type=1 && export TF_CPP_MIN_LOG_LEVEL=0

-------------------------------
#TPU Pods

export PROJECT_ID=lgai-vision-tpu
export TPU_NAME=tpu-pod-32a
export ZONE=europe-west4-a
export RUNTIME_VERSION=v2-alpha

gcloud alpha compute tpus tpu-vm create ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --accelerator-type v3-512 \
--version ${RUNTIME_VERSION}  --reserved 

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID}

gcloud compute config-ssh

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "git clone https://github.com/tgisaturday/dalle-lightning.git"


gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "cd dalle-lightning && git pull"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "pip3 install -r dalle-lightning/requirements.txt"
  
gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "sudo apt-get -y update && sudo apt-get -y install nfs-common"


gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "sudo mkdir -p /datasets && sudo mount 10.46.147.34:/hyperdata /datasets"


python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-32a --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --model vqvae --fake_data 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-32b --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --model vqvae --fake_data 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-64 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --model vqvae --fake_data --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-512 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --fake_data --model vqvae --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --fake_data --model vqvae --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_dalle.py --use_tpus --fake_data --debug --xla_stat 



gcloud compute --project=lgai-vision-tpu instances create pod-ctrl-32\
  --zone=europe-west4-a  \
  --machine-type=n1-standard-1  \
  --image-family=torch-xla \
  --image-project=ml-images  \
  --boot-disk-size=200GB \
  --scopes=https://www.googleapis.com/auth/cloud-platform


gcloud compute config-ssh
conda activate torch-xla-1.8.1

export TPU_NAME=tpu-vm-pod-32




python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-32 --restart-tpuvm-pod --env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4  -- python3 /home/taehoon.kim/vqgan/main.py --use_tpus


----------------------


export PROJECT_ID=lgai-vision-tpu
export TPU_NAME=tpu-vm-pod-128
export ZONE=europe-west4-a
export RUNTIME_VERSION=v2-alpha

gcloud alpha compute tpus tpu-vm create ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --accelerator-type v3-256 \
--version ${RUNTIME_VERSION}  --reserved --metadata startup-script='#! /bin/bash
cd /home/taehoon.kim/
mkdir coco_bucket
gcsfuse lgaivision-coco-eu coco_bucket
mkdir coco
cp coco_bucket/train2017.zip coco/
cd coco
unzip train2017.zip
cd ..
cp -r coco_bucket/taming-transformers/ /home/taehoon.kim/ 
fusermount -u /home/taehoon.kim/coco_bucket/

cd taming-transformers
pip3 install -r requirements.txt
cd ..
mkdir /home/taehoon.kim/temp/
chmod -R 777 /home/taehoon.kim/coco_bucket
chmod -R 777 /home/taehoon.kim/taming-transformers/
chmod -R 777 /home/taehoon.kim/coco
chmod -R 777 /home/taehoon.kim/temp
EOF'


